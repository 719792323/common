# 架构

[架构介绍](https://github.com/javahongxi/whatsmars/wiki/rocketmq-%E5%90%90%E8%A1%80%E6%80%BB%E7%BB%93)



# 使用

[集中SpringBoot](https://blog.csdn.net/hundan_520520/article/details/129666625)



# 消息队列公用内容

### 什么是消息队列

消息队列是**一个存放消息的容器**，当我们需要使用消息的时候，直接从容器中取出消息供自己使用即可。由于队列 Queue 是**一种先进先出的数据结构**，所以消费消息时也是按照顺序来消费的。使用消息队列可以**降低系统耦合性、实现任务异步、有效地进行流量削峰**，是分布式和微服务系统中重要的组件之一。

### 消息队列有什么用

1. **通过异步处理提高系统性能（减少响应所需时间）**

   有些业务调用链可能很长，直接用RPC逐级调用用户体验差

   * 直接调用链路返回时间550ms

   ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef380429cf373e.jpg)

   * 基于消息队列异步消费链路时间160ms

   ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef38124f55eaea.jpg)

2. **削峰/限流**

   > 怎么限制消费者消费速率
   >
   > * rocketmq可以通过设置`Consumer`端的`consumeMessageBatchMaxSize`和`pullInterval`属性来限制消费速率。`consumeMessageBatchMaxSize`属性决定了每次批量消费的最大消息数。通过减少批量大小，可以分散消费请求，间隔更长，达到限制速率的效果。`pullInterval`属性定义了`Consumer`拉取消息的间隔时间，增加这个值会减慢消费速率。

   先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。

3. **降低系统耦合性(pub/sub模型)**

   使用消息队列还可以降低系统耦合性。我们知道**如果模块之间不存在直接调用（JVM内部可以使用EventBus）**，那么新增模块或者修改模块就对其他模块影响较小，这样系统的可扩展性无疑更好一些。还是直接上图吧

### 消息队列事务

[rmq事务优缺点](https://mp.weixin.qq.com/s/cBx1l1zaThN6_808fMl27g)

消息队列事务允许事件流生产、处理、消费的整个过程定义为一个原子操作，MQ 的事务消息使用的是两阶段提交 (2PC)。。

1. MQ 发送方(比如物流服务) 在消息队列上开启一个事务，然后发送一个“半消息”给 MQ Server/Broker。事务提交之前，半消息对于 MQ订阅方/消费者 (比如第三方通知服务)不可见
2. “半消息”发送成功的话，MQ 发送方就开始执行本地事务。
3. MQ 发送方的本地事务执行成功的话，“半消息”变成正常消息，可以正常被消费。MQ 发送方的本地事务执行失败的话，会直接回滚。

##### MQ发送或回滚消息失败时会发生什么

RocketMQ 中的 Broker 会定期去 MQ 发送方上反查这事务的本地事务的执行情况，并根据反查结果决定提交或者回滚这个事务。事务反查机制的实现依赖于我们业务代码实现的对应的接口，比如你要查看创建物流信息的本地事务是否执行成功的话，直接在数据库中查询对应的物流信息是否存在即可。

##### MQ消息如果没有被正常消费会发生什么

消息消费失败的话，RocketMQ 会**自动进行消费重试**。如果超过最大重试次数这个消息还是没有正确消费，RocketMQ 就会认为这个消息有问题，然后将其放到**死信队列**。死信队列消息需要人工处理

### 消息队列问题

**系统可用性降低：** 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑**消息丢失**或者说 **MQ 挂掉**等等的情况，但是，引入 MQ 之后你就需要去考虑了！

**系统复杂性提高：** 加入 MQ 之后，你需要保证消息没有被**重复消费**、处理**消息丢失**的情况、保证**消息传递的顺序性**等等问题！

**一致性问题：** 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了

### RPC和消息队列区别

**从用途来看**：RPC 主要用来解决两个服务的远程通信问题，不需要了解底层网络的通信机制。通过 RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单。消息队列主要用来降低系统耦合性、实现任务异步、有效地进行流量削峰。

**从通信方式来看**：RPC 是双向直接网络通讯，消息队列是单向引入中间载体的网络通讯。

**从架构上来看**：消息队列需要把消息存储起来，RPC 则没有这个要求，因为前面也说了 RPC 是双向直接网络通讯。

**从请求处理的时效性来看**：通过 RPC 发出的调用一般会立即被处理，存放在消息队列中的消息并不一定会立即被处理。

### 消息队列选型

| 对比方向 | 概要                                                         |
| -------- | ------------------------------------------------------------ |
| 吞吐量   | 万级的 ActiveMQ 和 RabbitMQ 的吞吐量（ActiveMQ 的性能最差）要比十万级甚至是百万级的 RocketMQ 和 Kafka 低一个数量级。 |
| 可用性   | 都可以实现高可用。ActiveMQ 和 RabbitMQ 都是基于主从架构实现高可用性。RocketMQ 基于分布式架构。 Kafka 也是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 时效性   | RabbitMQ 基于 Erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级，其他几个都是 ms 级。 |
| 功能支持 | Pulsar 的功能更全面，支持多租户、多种消费模式和持久性模式等功能，是下一代云原生分布式消息流平台。 |
| 消息丢失 | ActiveMQ 和 RabbitMQ 丢失的可能性非常低， Kafka、RocketMQ 和 Pulsar 理论上可以做到 0 丢失。 |

**总结：**

- ActiveMQ 的社区算是比较成熟，但是较目前来说，**ActiveMQ 的性能比较差**，而且版本迭代很慢，不推荐使用，已经被淘汰了。
- RabbitMQ 在**吞吐量方面虽然稍逊于** Kafka、RocketMQ 和 Pulsar，但是由于它基于 Erlang 开发，所以**并发能力很强，性能极其好，延时很低，达到微秒级**。但是也因为 RabbitMQ 基于 Erlang 开发，所以国内很少有公司有实力做 Erlang 源码级别的研究和定制。如果业务场景对并发量要求不是太高（十万级、百万级），那这几种消息队列中，RabbitMQ 或许是你的首选。
- RocketMQ 和 Pulsar **支持强一致性**，对消息一致性要求比较高的场景可以使用。
- RocketMQ 阿里出品，Java 系开源项目，源代码我们可以直接阅读，然后可以定制自己公司的 MQ，并且 RocketMQ 有阿里巴巴的实际业务场景的实战考验。
- Kafka 的特点其实很明显，**就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展**。同时 Kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。**Kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响**，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

# RocketMQ内容

### 队列主题模型

* 队列模型

  存储消息的数据结构，先进先出

* 主题模型

  在主题模型中，消息的生产者称为 **发布者(Publisher)** ，消息的消费者称为 **订阅者(Subscriber)** ，存放消息的容器称为 **主题(Topic)** 发布者将消息发送到指定主题中，订阅者需要 **提前订阅主题** 才能接受特定主题的消息
  
  **RocketMQ中由三个角色模型：**
  
  > - `Producer Group` 生产者组：代表某一类的生产者，比如我们有多个秒杀系统作为生产者，这多个合在一起就是一个 `Producer Group` 生产者组，它们一般生产相同的消息。
  > - `Consumer Group` 消费者组：代表某一类的消费者，比如我们有多个短信系统作为消费者，这多个合在一起就是一个 `Consumer Group` 消费者组，它们一般消费相同的消息。
  > - `Topic` 主题：代表一类消息，比如订单消息，物流消息等等。
  
  **主题中存在多个队列**，生产者每次生产消息之后是指定主题中的某个队列发送消息的。**每个主题中都有多个队列**(分布在不同的 `Broker`中，如果是集群的话，`Broker`又分布在不同的服务器中)，集群消费模式下，一个消费者集群多台机器共同消费一个 `topic` 的多个队列，**一个队列只会被一个消费者消费**。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。就像上图中 `Consumer1` 和 `Consumer2` 分别对应着两个队列，而 `Consumer3` 是没有队列对应的，所以一般来讲要控制 **消费者组中的消费者个数和主题中队列个数相同** 。当然也可以消费者个数小于队列个数，只不过不太建议。

![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef383d3e8c9788.jpg)

###  队列消费问题

#### 消费者组为什么要在每个队列上维护一个消费位置

每个消费者组在每个队列中的消费位置都是不同的。如果此时**有多个消费者组**，那么消息被一个消费者组消费完之后是不会删除的(因为其它消费者组也需要)，它仅仅是为每个消费者组维护一个 **消费位移(offset)** ，每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。

![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef3857fefaa079.jpg)

#### 消息堆积怎么解决

* 增加Broker数量

  > 最快速解决消息堆积问题的方法还是增加消费者实例，不过 **同时你还需要增加每个主题的队列数量** 。别忘了在 `RocketMQ` 中，**一个队列只会被一个消费者消费** ，如果你仅仅是增加消费者实例就会出现我一开始给你画架构图的那种情况。

* 限流熔断

  当流量到峰值的时候是因为生产者生产太快，我们可以使用一些 **限流降级** 的方法，当然你也可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。

#### 消费回溯是什么

回溯消费是指 `Consumer` 已经消费成功的消息，由于业务上需求需要重新消费，在`RocketMQ` 中， `Broker` 在向`Consumer` 投递成功消息后，**消息仍然需要保留** 。并且重新消费一般是按照时间维度，例如由于 `Consumer` 系统故障，恢复后需要重新消费 1 小时前的数据，那么 `Broker` 要提供一种机制，可以按照时间维度来回退消费进度。**`RocketMQ` 支持按照时间回溯消费，时间维度精确到毫秒**。

### RocketMQ架构

`RocketMQ` 技术架构中有四大角色 `NameServer`、`Broker`、`Producer`、`Consumer` 。

- `Broker`：主要负责消息的存储、投递和查询以及服务高可用保证。说白了就是消息队列服务器嘛，生产者生产消息到 `Broker` ，消费者从 `Broker` 拉取消息并消费。

  > **一个 `Topic` 分布在多个 `Broker`上，一个 `Broker` 可以配置多个 `Topic` ，它们是多对多的关系**。
  >
  > 如果某个 `Topic` 消息量很大，应该给它多配置几个队列(上文中提到了提高并发能力)，并且 **尽量多分布在不同 `Broker` 上，以减轻某个 `Broker` 的压力** 。**同一个topic中的多个队列可以分布在同一个broker中**。

  ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef38687488a5a4.jpg)

* `NameServer`：其实是一个 **注册中心** ，主要提供两个功能：**Broker 管理** 和 **路由信息管理** 。说白了就是 `Broker` 会将自己的信息注册到 `NameServer` 中，此时 `NameServer` 就存放了很多 `Broker` 的信息(Broker 的路由表)，消费者和生产者就从 `NameServer` 中获取路由表然后照着路由表的信息和对应的 `Broker` 进行通信(生产者和消费者定期会向 `NameServer` 去查询相关的 `Broker` 的信息)
* `Producer`：消息发布的角色，支持分布式集群方式部署。说白了就是生产者。
* `Consumer`：消息消费的角色，支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。说白了就是消费者。

#### 架构分析

- `Broker`**做了集群并且还进行了主从部署** ，由于消息分布在各个 `Broker` 上，一旦某个 `Broker` 宕机，则该`Broker` 上的消息读写都会受到影响。所以 `Rocketmq` 提供了 `master/slave` 的结构，`salve` 定时从 `master` 同步数据(同步刷盘或者异步刷盘)，如果 `master` 宕机，**则 `slave` 提供消费服务，但是不能写入消息**
-  `NameServer` 做了集群部署，但是它是 **去中心化** 的。也就意味着它没有主节点， `NameServer` 的所有节点是没有进行 `Info Replicate` 的，在 `RocketMQ` 中是通过 **单个 Broker 和所有 NameServer 保持长连接** ，并且在每隔 30 秒 `Broker` 会向所有 `Nameserver` 发送心跳，心跳包含了自身的 `Topic` 配置信息，这个步骤就对应这上面的 `Routing Info`
- 在生产者需要向 `Broker` 发送消息的时候，**需要先从 `NameServer` 获取关于 `Broker` 的路由信息**，然后通过 **轮询** 的方法去向每个队列中生产数据以达到 **负载均衡** 的效果
- 消费者通过 `NameServer` 获取所有 `Broker` 的路由信息后，向 `Broker` 发送 `Pull` 请求来获取消息数据。`Consumer` 可以以两种模式启动—— **广播（Broadcast）和集群（Cluster）**。广播模式下，一条消息会发送给 **同一个消费组中的所有消费者** ，集群模式下消息只会发送给一个消费者

![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef386fa3be1e53.jpg)

#### RocketMQ如何保证高性能读写

* 传统IO读写

  > 1. 用户调用 read()方法，开始读取数据，此时发生一次上下文从用户态到内核态的切换，也就是图示的切换 1
  > 2. 将磁盘数据通过 DMA 拷贝到内核缓存区
  > 3. 将内核缓存区的数据拷贝到用户缓冲区，这样用户，也就是我们写的代码就能拿到文件的数据
  > 4. read()方法返回，此时就会从内核态切换到用户态，也就是图示的切换 2
  > 5. 当我们拿到数据之后，就可以调用 write()方法，此时上下文会从用户态切换到内核态，即图示切换 3
  > 6. CPU 将用户缓冲区的数据拷贝到 Socket 缓冲区
  > 7. 将 Socket 缓冲区数据拷贝至网卡
  > 8. write()方法返回，上下文重新从内核态切换到用户态，即图示切换 4

  整个过程**发生了 4 次上下文切换和 4 次数据的拷贝**，这在高并发场景下肯定会严重影响读写性能故引入了零拷贝技术

  ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/31699457085_.pic.jpg)

* 零拷贝技术(mmap)

  mmap（memory map）是**一种内存映射文件的方法**，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。简单地说就是**内核缓冲区和应用缓冲区共享**，从而减少了从读缓冲区到用户缓冲区的一次 CPU 拷贝。当用户发起 mmap 调用的时候会发生上下文切换 1，进行内存映射，然后数据被拷贝到内核缓冲区，mmap 返回，发生上下文切换 2；随后用户调用 write，发生上下文切换 3，将内核缓冲区的数据拷贝到 Socket 缓冲区，write 返回，发生上下文切换 4。发生 4 次上下文切换和 3 次 IO 拷贝操作。

  ```java
  //java实现
  FileChannel fileChannel = new RandomAccessFile("test.txt", "rw").getChannel();
  MappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, fileChannel.size());
  ```

  

  ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/41699457086_.pic.jpg)

* 零拷贝(sendfile)

  sendfile()跟 mmap()一样，也会减少一次 CPU 拷贝，但是它同时也会减少两次上下文切换。**sendfile，并没有文件的读写操作，而是直接将文件的数据传输到 target 目标缓冲区，也就是说，sendfile 是无法知道文件的具体的数据的；但是 mmap 不一样，他是可以修改内核缓冲区的数据的。假设如果需要对文件的内容进行修改之后再传输，只有 mmap 可以满足**。

  ```java
  //java实现
  FileChannel channel = FileChannel.open(Paths.get("./test.txt"), StandardOpenOption.WRITE, StandardOpenOption.CREATE);
  //调用transferTo方法向目标数据传输
  channel.transferTo(position, len, target);
  ```

  

  ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/51699457087_.pic.jpg)

#### RocketMQ刷盘机制

RMQ支持同步与异步刷盘，在同步刷盘中需要等待一个刷盘成功的 `ACK` ，同步刷盘对 `MQ` 消息可靠性来说是一种不错的保障，但是 **性能上会有较大影响** ，一般地适用于金融等特定业务场景。而异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行， **降低了读写延迟** ，提高了 `MQ` 的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景。一般地，**异步刷盘只有在 `Broker` 意外宕机的时候会丢失部分数据**，你可以设置 `Broker` 的参数 `FlushDiskType` 来调整你的刷盘策略(ASYNC_FLUSH 或者 SYNC_FLUSH)。

![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef387fba311cda-20230814005009889.jpg)

#### RocketMQ同步机制

同步复制和异步复制主要是指的 `Borker` 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。

- 同步复制：也叫 “同步双写”，也就是说，**只有消息同步双写到主从节点上时才返回写入成功** 。

- 异步复制：**消息写入主节点之后就直接返回写入成功** 。

  **异步复制会不会也像异步刷盘那样影响消息的可靠性呢**，答案是不会的，因为两者就是不同的概念，对于消息可靠性是通过不同的刷盘策略保证的，而像异步同步复制策略仅仅是影响到了 **可用性** 。为什么呢？其主要原因**是 `RocketMQ` 是不支持自动主从切换的，当主节点挂掉之后，生产者就不能再给这个主节点生产消息**。

  比如这个时候采用异步复制的方式，在主节点还未发送完需要同步的消息的时候主节点挂掉了，这个时候从节点就少了一部分消息。但是此时生产者无法再给主节点生产消息了，**消费者可以自动切换到从节点进行消费**(仅仅是消费)，所以在主节点挂掉的时间只会产生主从结点短暂的消息不一致的情况，降低了可用性，而当主节点重启之后，从节点那部分未来得及复制的消息还会继续复制。

  在单主从架构中，如果一个主节点挂掉了，那么也就意味着整个系统不能再生产了。那么这个可用性的问题能否解决呢？**一个主从不行那就多个主从的呗**，别忘了在我们最初的架构图中，每个 `Topic` 是分布在不同 `Broker` 中的。但是这种复制方式同样也会带来一个问题，那就是无法保证 **严格顺序** 。在上文中我们提到了如何保证的消息顺序性是通过将一个语义的消息发送在同一个队列中，使用 `Topic` 下的队列来保证顺序性的。如果此时我们主节点 A 负责的是订单 A 的一系列语义消息，然后它挂了，这样其他节点是无法代替主节点 A 的，如果我们任意节点都可以存入任何消息，那就没有顺序性可言了。而在 `RocketMQ` 中采用了 `Dledger` 解决这个问题。他要求在写入消息的时候，要求**至少消息复制到半数以上的节点之后**，才给客⼾端返回写⼊成功，并且它是⽀持通过选举来动态切换主节点的。这里我就不展开说明了，读者可以自己去了解。

  注意：下图TopicA中Queue0分布在了多个Broker中。

  ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef38687488a5asadasfg4.jpg)

#### RocketMQ存储文件

`RocketMQ` 消息存储架构中的三大角色——`CommitLog`、`ConsumeQueue` 和 `IndexFile` 

- `CommitLog`（存储数据的文件）：**消息主体以及元数据的存储主体**，存储 `Producer` 端写入的消息主体内容,消息内容不是定长的。单个文件大小默认 1G ，文件名长度为 20 位，左边补零，剩余为起始偏移量，比如 00000000000000000000 代表了第一个文件，起始偏移量为 0，文件大小为 1G=1073741824；当第一个文件写满了，第二个文件为 00000000001073741824，起始偏移量为 1073741824，以此类推。消息主要是**顺序写入日志文件**，当文件满了，写入下一个文件。

- `ConsumeQueue`（Commitlog的索引文件）：消息消费队列，**引入的目的主要是提高消息消费的性能**(我们再前面也讲了)，由于`RocketMQ` 是基于主题 `Topic` 的订阅模式，消息消费是针对主题进行的，如果要遍历 `commitlog` 文件中根据 `Topic` 检索消息是非常低效的。`Consumer` 即可根据 `ConsumeQueue` 来查找待消费的消息。其中，`ConsumeQueue`（逻辑消费队列）**作为消费消息的索引**，保存了指定 `Topic` 下的队列消息在 `CommitLog` 中的**起始物理偏移量 `offset` \**，消息大小 `size` 和消息 `Tag` 的 `HashCode` 值。\**`consumequeue` 文件可以看成是基于 `topic` 的 `commitlog` 索引文件**，故 `consumequeue` 文件夹的组织方式如下：topic/queue/file 三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样 `consumequeue` 文件采取定长设计，每一个条目共 20 个字节，分别为 8 字节的 `commitlog` 物理偏移量、4 字节的消息长度、8 字节 tag `hashcode`，单个文件由 30W 个条目组成，可以像数组一样随机访问每一个条目，每个 `ConsumeQueue`文件大小约 5.72M；

- `IndexFile`（方便回溯的索引文件）：`IndexFile`（索引文件）提供了一种可以通过 key 或时间区间来查询消息的方法。这里只做科普不做详细介绍。

 `RocketMQ` 采用的是 **混合型的存储结构** ，即为 `Broker` 单个实例下所有的队列共用一个日志数据文件来存储消息。有意思的是在同样高并发的 `Kafka` 中会为每个 `Topic` 分配一个存储文件。这就有点类似于我们有一大堆书需要装上书架，`RockeMQ` 是不分书的种类直接成批的塞上去的，而 `Kafka` 是将书本放入指定的分类区域的。而 `RocketMQ` 为什么要这么做呢？原因是 **提高数据的写入效率** ，不分 `Topic` 意味着我们有更大的几率获取 **成批** 的消息进行数据写入，但也会带来一个麻烦就是读取消息的时候需要遍历整个大文件，这是非常耗时的。所以，在 `RocketMQ` 中又使用了 `ConsumeQueue` 作为每个队列的索引文件来 **提升读取消息的效率**。我们可以直接根据队列的消息序号，计算出索引的全局位置（索引序号*索引固定⻓度 20），然后直接读取这条索引，再根据索引中记录的消息的全局位置，找到消息。

![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef3884c02acc72.png)

  

### RocketMQ消息类型

#### 普通消息

要求数据传输通道具有可靠传输的能力，且对消息的处理时机、处理顺序没有特别要求。

**消费过程如下：**

1. 初始化：消息被生产者构建并完成初始化，待发送到服务端的状态。
2. 待消费：消息被发送到服务端，对消费者可见，等待消费者消费的状态。
3. 消费中：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。 此时服务端会等待消费者完成消费并提交消费结果，如果一定时间后没有收到消费者的响应，RocketMQ 会对消息进行重试处理。
4. 消费提交：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。RocketMQ 默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。
5. 消息删除：RocketMQ 按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。

#### 定时消息

分布式定时调度触发、任务超时处理等场景，需要实现精准、可靠的定时事件触发。定时消息仅支持在 MessageType 为 Delay 的主题内使用，即定时消息只能发送至类型为定时消息的主题中，**发送的消息的类型必须和主题的类型一致**。

**定时消息优点：**

- **精度高、开发门槛低**：基于消息通知方式不存在定时阶梯间隔。可以轻松实现任意精度事件触发，无需业务去重。
- **高性能可扩展**：传统的数据库扫描方式较为复杂，需要频繁调用接口扫描，容易产生性能瓶颈。RocketMQ 的定时消息具有高并发和水平扩展的能力。

**消费过程：**

1. 初始化：消息被生产者构建并完成初始化，待发送到服务端的状态。
2. 定时中：消息被发送到服务端，和普通消息不同的是，服务端不会直接构建消息索引，而是会将定时消息**单独存储在定时存储系统中**，等待定时时刻到达。
3. 待消费：定时时刻到达后，服务端将消息重新写入普通存储引擎，对下游消费者可见，等待消费者消费的状态。
4. 消费中：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。 此时服务端会等待消费者完成消费并提交消费结果，如果一定时间后没有收到消费者的响应，RocketMQ 会对消息进行重试处理。
5. 消费提交：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。RocketMQ 默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。
6. 消息删除：Apache RocketMQ 按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。

注意：定时消息的实现逻辑需要先经过定时存储等待触发，定时时间到达后才会被投递给消费者。因此，如果将大量定时消息的定时时间设置为同一时刻，则到达该时刻后会有大量消息同时需要被处理，会造成系统压力过大，导致消息分发延迟，影响定时精度。

#### 顺序消息

[官方资料](https://rocketmq.apache.org/zh/docs/4.x/producer/03message2)

顺序消息仅支持使用 MessageType 为 FIFO 的主题，即顺序消息只能发送至类型为顺序消息的主题中，发送的消息的类型必须和主题的类型一致。和普通消息发送相比，顺序消息发送必须要设置消息组。（推荐实现 MessageQueueSelector 的方式，见下文）。要保证消息的顺序性需要单一生产者串行发送。单线程使用 MessageListenerConcurrently 可以顺序消费，多线程环境下使用 MessageListenerOrderly 才能顺序消费。

#### 事务消息

事务消息是 Apache RocketMQ 提供的一种高级消息类型，支持在分布式场景下保障消息生产和本地事务的最终一致性。简单来讲，就是将本地事务（数据库的 DML 操作）与发送消息合并在同一个事务中。例如，新增一个订单。在事务未提交之前，不发送订阅的消息。发送消息的动作随着事务的成功提交而发送，随着事务的回滚而取消。当然真正地处理过程不止这么简单，包含了半消息、事务监听和事务回查等概念，下面有更详细的说明。

![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef38798d7a987f.png)

### RocketMQ生产者

#### 操作实践建议

* 生产者复用，不建议大量创建

  **Apache RocketMQ 的生产者和主题是多对多的关系**，**支持同一个生产者向多个主题发送消息**。对于生产者的创建和初始化，建议遵循够用即可、最大化复用原则，如果有需要发送消息到多个主题的场景，无需为每个主题都创建一个生产者

* 不建议频繁创建和销毁生产者

  Apache RocketMQ 的生产者是可以重复利用的底层资源，类似数据库的连接池。因此不需要在每次发送消息时动态创建生产者，且在发送结束后销毁生产者。这样频繁的创建销毁会在服务端产生大量短连接请求，严重影响系统性能

#### 生产者分组

RocketMQ 服务端 5.x 版本开始，**生产者是匿名的**，无需管理生产者分组（ProducerGroup）；对于历史版本服务端 3.x 和 4.x 版本，已经使用的生产者分组可以废弃无需再设置，且不会对当前业务产生影响。

### RocketMQ消费者

> * 消费者需要注意如何保证消息消费结果被RocketMQ知晓，否则会导致重复消费

#### 消费者类别分类

* PushConsumer

  **高度封装的消费者类型**，消费消息仅仅通过消费监听器监听并返回结果。**消息的获取、消费状态提交以及消费重试**都通过 RocketMQ 的客户端 SDK 完成

  PushConsumer 的消费监听器执行结果分为以下三种情况：

  - 返回消费成功：以 Java SDK 为例，返回`ConsumeResult.SUCCESS`，表示该消息处理成功，服务端按照消费结果更新消费进度。
  - 返回消费失败：以 Java SDK 为例，返回`ConsumeResult.FAILURE`，表示该消息处理失败，需要根据消费重试逻辑判断是否进行重试消费。
  - 出现非预期失败：例如抛异常等行为，该结果按照消费失败处理，需要根据消费重试逻辑判断是否进行重试消费。

  注意：使用 PushConsumer 消费者消费时，不允许使用以下方式处理消息，否则 RocketMQ 无法保证消息的可靠性

  > **错误方式一：**消息还未处理完成，就提前返回消费成功结果。此时如果消息消费失败，RocketMQ 服务端是无法感知的，因此不会进行消费重试。
  >
  > 错误方式二：在消费监听器内将消息再次分发到自定义的其他线程，消费监听器提前返回消费结果。此时如果消息消费失败，RocketMQ 服务端同样无法感知，因此也不会进行消费重试。
  >
  > ***PushConsumer 严格限制了消息同步处理及每条消息的处理超时时间，适用于以下场景：*** 
  >
  > - 消息处理时间可预估：**如果不确定消息处理耗时，经常有预期之外的长时间耗时的消息，PushConsumer 的可靠性保证会频繁触发消息重试机制造成大量重复消息**。
  > - 无异步化、高级定制场景：PushConsumer 限制了消费逻辑的线程模型，由客户端 SDK 内部按最大吞吐量触发消息处理。该模型开发逻辑简单，但是不允许使用异步化和自定义处理流程

* SimpleConsumer

  SimpleConsumer 是一种接口原子型的消费者类型，**消息的获取、消费状态提交以及消费重试都是通过消费者业务逻辑主动发起调用完成。**

  **SimpleConsumer 适用于以下场景：**

  - 消息处理时长不可控：如果消息处理时长无法预估，经常有长时间耗时的消息处理情况。建议使用 SimpleConsumer 消费类型，可以在消费时自定义消息的预估处理时长，若实际业务中预估的消息处理时长不符合预期，也可以通过接口提前修改。
  - 需要异步化、批量消费等高级定制场景：SimpleConsumer 在 SDK 内部没有复杂的线程封装，完全由业务逻辑自由定制，可以实现异步分发、批量消费等高级定制场景。
  - 需要自定义消费速率：SimpleConsumer 是由业务逻辑主动调用接口获取消息，因此可以自由调整获取消息的频率，自定义控制消费速率。

  ```java
  // 消费示例：使用 SimpleConsumer 消费普通消息，主动获取消息处理并提交。
  ClientServiceProvider provider = ClientServiceProvider.loadService();
  String topic = "YourTopic";
  FilterExpression filterExpression = new FilterExpression("YourFilterTag", FilterExpressionType.TAG);
  SimpleConsumer simpleConsumer = provider.newSimpleConsumerBuilder()
          // 设置消费者分组。
          .setConsumerGroup("YourConsumerGroup")
          // 设置接入点。
          .setClientConfiguration(ClientConfiguration.newBuilder().setEndpoints("YourEndpoint").build())
          // 设置预绑定的订阅关系。
          .setSubscriptionExpressions(Collections.singletonMap(topic, filterExpression))
          // 设置从服务端接受消息的最大等待时间
          .setAwaitDuration(Duration.ofSeconds(1))
          .build();
  try {
      // SimpleConsumer 需要主动获取消息，并处理。
      List<MessageView> messageViewList = simpleConsumer.receive(10, Duration.ofSeconds(30));
      messageViewList.forEach(messageView -> {
          System.out.println(messageView);
          // 消费处理完成后，需要主动调用 ACK 提交消费结果。
          try {
              simpleConsumer.ack(messageView);
          } catch (ClientException e) {
              logger.error("Failed to ack message, messageId={}", messageView.getMessageId(), e);
          }
      });
  } catch (ClientException e) {
      // 如果遇到系统流控等原因造成拉取失败，需要重新发起获取消息请求。
      logger.error("Failed to receive message", e);
  }
  ```


#### 消费者分组

消费者分组是多个消费行为一致的消费者的负载均衡分组。消费者分组不是具体实体而是一个逻辑资源。通过消费者分组实现消费性能的水平扩展以及高可用容灾。

消费者分组中的订阅关系、投递顺序性、消费重试策略是一致的。

- 订阅关系：Apache RocketMQ 以消费者分组的粒度管理订阅关系，实现订阅关系的管理和追溯。
- 投递顺序性：Apache RocketMQ 的服务端将消息投递给消费者消费时，支持顺序投递和并发投递，投递方式在消费者分组中统一配置。
- 消费重试策略： 消费者消费消息失败时的重试策略，包括重试次数、死信队列设置等。

#### 如何保证顺序消费和避免重复消费

* 顺序消费

  **`RocketMQ` 在主题上是无序的、它只有在*`队列层面`*才是保证有序的**。

  * 普通顺序

    普通顺序是指 消费者通过 **同一个消费队列收到的消息是有顺序的** ，不同消息队列收到的消息则可能是无顺序的。普通顺序消息在 `Broker` **重启情况下不会保证消息顺序性** (短暂时间) 。

  * 严格顺序

    严格顺序是指 消费者收到的 **所有消息** 均是有顺序的。严格顺序消息 **即使在异常情况下也会保证消息的顺序性** 。

  严格顺序看起来虽好，实现它可会付出巨大的代价。如果你使用严格顺序模式，`Broker` 集群中只要有一台机器不可用，则整个集群都不可用。现在主要场景也就在 `binlog` 同步。

  `Producer` 生产消息的时候会进行轮询(取决你的负载均衡策略)来向同一主题的不同消息队列发送消息。那么如果此时我有几个消息分别是同一个订单的创建、支付、发货，在轮询的策略下这 **三个消息会被发送到不同队列** ，因为在不同的队列此时就无法使用 `RocketMQ` 带来的队列有序特性来保证消息有序性了。为保证顺序，需要处理的仅仅是将同一语义下的消息放入同一个队列(比如这里是同一个订单)，那我们就可以使用 **Hash 取模法** 来保证同一个订单在同一个队列中就行了。

  > RocketMQ 实现了两种队列选择算法，也可以自己实现
  >
  > - 轮询算法
  >
  >   - 轮询算法就是向消息指定的 topic 所在队列中依次发送消息，保证消息均匀分布，**是 RocketMQ 默认队列选择算法**
  >
  > - 最小投递延迟算法
  >
  >   - 每次消息投递的时候统计消息投递的延迟，选择队列时优先选择消息延时小的队列，导致消息分布不均匀,按照如下设置即可。
  >
  >     ```java
  >     producer.setSendLatencyFaultEnable(true);
  >     ```
  >
  > - 继承 MessageQueueSelector 实现
  >
  >   ```java
  >   SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
  >       @Override
  >       public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
  >           //从mqs中选择一个队列,可以根据msg特点选择
  >           return null;
  >       }
  >   }, new Object());
  >   ```

  ![img](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/16ef3874585e096e.jpg)

  选择队列后会与 Broker 建立连接，通过网络请求将消息发送到 Broker 上，如果 Broker 挂了或者网络波动发送消息超时此时 RocketMQ 会进行重试。重新选择其他 Broker 中的消息队列进行发送，默认重试两次，可以手动设置。

  ```java
  producer.setRetryTimesWhenSendFailed(5);
  ```

* 重复消费
  * 避免触发重复消费：保证消费后，消息队列收到消费响应
  * 设计幂等消费方案：如果发生了重复消费，应该设计幂等写入方案